{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch framework의 기본 사용법을 익힙니다. \n",
    "- Neural Network 모델을 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직관적이고 간결한 코드\n",
    "- Define by Run 방식 (Tensorflow - Define and Run 방식)\n",
    "- Numpy와 높은 호환성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.6.0\n"
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu number 지정\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # 1차 과정 gpu number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PyTorch: Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch의 가장 기본적인 자료 구조. n 차원 array + GPU 연산이 가능한 자료 구조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 2., 3.])\nType of t_1:  <class 'torch.Tensor'>\nShape of t_1:  torch.Size([3])\n\ntensor([[1., 2., 3.],\n        [1., 2., 3.]])\nType of t_2:  <class 'torch.Tensor'>\nShape of t_2:  torch.Size([2, 3])\n"
    }
   ],
   "source": [
    "t_1 = torch.Tensor([1, 2, 3])\n",
    "t_2 = torch.Tensor([[1, 2, 3], [1, 2, 3]])\n",
    "print(t_1)\n",
    "print('Type of t_1: ', type(t_1))\n",
    "print('Shape of t_1: ', t_1.shape)  # 매우 자주 쓰는 함수\n",
    "print('')\n",
    "print(t_2)\n",
    "print('Type of t_2: ', type(t_2))\n",
    "print('Shape of t_2: ', t_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 2., 3.])\nType of t_3:  <class 'torch.Tensor'>\nShape of t_3:  torch.Size([3])\n"
    }
   ],
   "source": [
    "n_1 = np.array([1, 2, 3])\n",
    "t_3 = torch.Tensor(n_1)  # torch.Tensor(np.array([1, 2, 3]))\n",
    "print(t_3)\n",
    "print('Type of t_3: ', type(t_3))\n",
    "print('Shape of t_3: ', t_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 명시적으로 Tensor의 값을 지정해주는 것 외에도, 자주 사용하는 tensor 선언 방법은 함수로 제공됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.rand(size)는 uniform distribution U(0, 1)에서 random sampling한 값으로 tensor를 구성합니다.\n",
    "x_1 = torch.rand(5)  # 1D (5) tensor (예: vector)\n",
    "x_2 = torch.rand(5, 5)  # 2D (5 x 5) tensor (예: matrix)\n",
    "x_3 = torch.rand(5, 5, 3)  # 3D (5 x 5 x 3) tensor (예: image)\n",
    "x_4 = torch.rand(16, 5, 3, 3)  # 4D (16 x 5 x 3 x 3) tensor (예: image + mini batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0.9872, 0.6907, 0.9589, 0.8636, 0.9627],\n        [0.5250, 0.6375, 0.8764, 0.1667, 0.8988],\n        [0.3709, 0.0994, 0.1751, 0.5667, 0.3909],\n        [0.2569, 0.7077, 0.7792, 0.2046, 0.9458],\n        [0.4589, 0.4674, 0.1021, 0.4699, 0.5162]])\n"
    }
   ],
   "source": [
    "print(x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그 중 가장 자주 쓰이는 방법들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1.])\ntensor([0., 0., 0.])\ntensor([2.8674, 0.7088, 0.8345])\n"
    }
   ],
   "source": [
    "print(torch.ones(3))\n",
    "print(torch.zeros(3))\n",
    "print(torch.randn(3))  # x ~ N(0, I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_04.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5, 10)\n",
    "b = torch.zeros(5, 10)\n",
    "c = torch.randn(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([15, 10])\n"
    }
   ],
   "source": [
    "d = torch.cat((a, b, c), 0)  # 자주 사용하는 함수입니다.\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([-1.0342, -2.0124,  1.9993,  1.1479,  1.0816, -1.4635,  0.4862, -1.8543,\n         1.5914,  1.0380])\n"
    }
   ],
   "source": [
    "print(d[0])\n",
    "print(d[5])\n",
    "print(d[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000, -1.0342, -0.0629,  1.0077, -1.2060,  0.3283])\n"
    }
   ],
   "source": [
    "print(d[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for dimension 1 with size 10",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-87cb62489066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 1 with size 10"
     ]
    }
   ],
   "source": [
    "print(d[:, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.stack([a, b, c], 0)    # 자주 사용하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 5, 10])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\ntorch.Size([5, 10])\n"
    }
   ],
   "source": [
    "print(e[0])\n",
    "print(e[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n          1.0000,  1.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000],\n        [-1.0342, -2.0124,  1.9993,  1.1479,  1.0816, -1.4635,  0.4862, -1.8543,\n          1.5914,  1.0380]])\ntorch.Size([3, 10])\n"
    }
   ],
   "source": [
    "print(e[:, 0])\n",
    "print(e[:, 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-1.0342, -0.0629,  1.0077, -1.2060,  0.3283]])\ntorch.Size([3, 5])\n"
    }
   ],
   "source": [
    "print(e[:, :, 0])\n",
    "print(e[:, :, 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tensor 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 같은 shape의 tensor끼리 더하기 연산을 할 수 있는 여러가지 방법들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([2., 4., 6.])\ntensor([2., 4., 6.])\ntensor([2., 4., 6.])\n"
    }
   ],
   "source": [
    "print(t_1 + t_3)\n",
    "print(torch.add(t_1, t_3))\n",
    "print(t_1.add(t_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0., 0., 0.])\ntensor([1., 4., 9.])\ntensor([1., 1., 1.])\n"
    }
   ],
   "source": [
    "print(t_1 - t_3)\n",
    "print(t_1 * t_3)\n",
    "print(t_1 / t_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 질문: 다른 shape의 tensor들을 이용하여 연산을 하면 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1 = torch.Tensor([[0, 0, 0], [10, 10, 10], [20, 20, 20], [30, 30, 30]])\n",
    "t_2 = torch.Tensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 3])\ntorch.Size([3])\n"
    }
   ],
   "source": [
    "print(t_1.shape)\n",
    "print(t_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.,  1.,  2.],\n        [10., 11., 12.],\n        [20., 21., 22.],\n        [30., 31., 32.]])\n"
    }
   ],
   "source": [
    "result = t_1 + t_2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 3])\n"
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 서로 다른 dimension의 두 tensor가 있을 때, 더 작은 dimension의 tensor에 새로운 dimension이 추가된다. 이때 tensor shape 상으로는 왼쪽 부분에 shape 1의 새로운 dimension이 생긴다.\n",
    "2. dimension 중 서로 shape이 안 맞는 부분이 있다면, 둘 중 shape이 1인 부분을 조정하여 shape을 맞춰준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1., 1., 1.]])\ntensor([[1., 1., 1., 1., 1.]])\n"
    }
   ],
   "source": [
    "print(torch.zeros(1, 5) + torch.ones(5))\n",
    "print(torch.zeros(1, 5) + torch.ones(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[1., 1., 1., 1., 1.]]])\ntensor([[[1., 1., 1., 1., 1.]]])\ntensor([[[1., 1., 1., 1., 1.]]])\n"
    }
   ],
   "source": [
    "print(torch.zeros(1, 1, 5) + torch.ones(5))\n",
    "print(torch.zeros(1, 1, 5) + torch.ones(1, 5))\n",
    "print(torch.zeros(1, 1, 5) + torch.ones(1, 1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3])\ntorch.Size([1])\n"
    }
   ],
   "source": [
    "print(torch.Tensor([1, 2, 3]).shape)\n",
    "print(torch.Tensor([10]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([11., 12., 13.])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "torch.Tensor([1, 2, 3]) + torch.Tensor([10])  # shape: 3 +  shape: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([11., 12., 13.])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "torch.Tensor([1, 2, 3]) + torch.Tensor([10, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First rule + Second rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\ntensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])\n"
    }
   ],
   "source": [
    "print(torch.zeros(2, 3, 4) + torch.ones(3, 4))\n",
    "print(torch.zeros(2, 3, 4) + torch.ones(1, 3, 4))\n",
    "print(torch.zeros(2, 3, 4) + torch.ones(2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting이 안되는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7787970ca5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 안되는 이유는?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.zeros(3, 4) + torch.ones(1, 2)\n",
    "# 안되는 이유는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-173dd9d25862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 안되는 이유는?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.zeros(3, 4) + torch.ones(2)\n",
    "# 안되는 이유는?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퀴즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음 두 tensor들을 이용하여, Broadcasting 연산이 가능한지 판단하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [5, 10, 2] shape Tensor & [1, 2] shape Tensor --> YES\n",
    "2. [3, 12, 6] shape Tensor & [12, 6] shape Tensor --> YES\n",
    "3. [4, 8, 4] shape Tensor & [4, 2] shape Tensor --> NO\n",
    "4. [2, 5] shape Tensor & [3, 2, 5] shape Tensor --> YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[2., 2., 2., 2., 2.],\n         [2., 2., 2., 2., 2.]],\n\n        [[2., 2., 2., 2., 2.],\n         [2., 2., 2., 2., 2.]],\n\n        [[2., 2., 2., 2., 2.],\n         [2., 2., 2., 2., 2.]]])\n"
    }
   ],
   "source": [
    "# print(torch.ones(5, 10, 2) + torch.ones(1, 2))\n",
    "# print(torch.ones(3, 12, 6) + torch.ones(12, 6))\n",
    "# print(torch.ones(4, 8, 4) + torch.ones(4, 2))\n",
    "print(torch.ones(2, 5) + torch.ones(3, 2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 GPU를 사용하여 Tensor 연산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3)\n",
    "b = torch.randn(100, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\ncpu\n"
    }
   ],
   "source": [
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\n"
    }
   ],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 사용 tensor\n",
    "a = a.to('cuda')\n",
    "b = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\ncuda:0\n"
    }
   ],
   "source": [
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\n"
    }
   ],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\n"
    }
   ],
   "source": [
    "print(c.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([2, 3])\n"
    }
   ],
   "source": [
    "# input data -> 학습 대상이 아님\n",
    "X = torch.Tensor([[1, 2, 3], [3, 4, 5]])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 1])\n"
    }
   ],
   "source": [
    "# weight -> 학습 대상\n",
    "W = torch.ones(3, 1, requires_grad=True)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "print(W.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": [
    "print(X.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": [
    "# bias -> 학습 대상\n",
    "b = torch.Tensor([0.1])\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "b.requires_grad_()\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 6.1000],\n        [12.1000]], grad_fn=<AddBackward0>)\ntorch.Size([2, 1])\n"
    }
   ],
   "source": [
    "Y = torch.matmul(X, W) + b\n",
    "# (2 x 3) (3 x 1) => (2 x 1)\n",
    "# (2 x 1) + (1) => (2 x 1)\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(18.2000, grad_fn=<SumBackward0>)\n"
    }
   ],
   "source": [
    "result = Y.sum()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss와 연관이 있고, requires_grad=True인 parameter의 gradient값을 자동으로 계산\n",
    "result.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[4.],\n        [6.],\n        [8.]])"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad=True이지만 gradient 계산을 필요로 하지 않을 때\n",
    "with torch.no_grad():\n",
    "    X = torch.Tensor([[1, 2, 3], [3, 4, 5]])\n",
    "    W = torch.ones(3, 1, requires_grad=True)\n",
    "    b = torch.Tensor([0.1])\n",
    "    b.requires_grad_ = True\n",
    "    Y = torch.matmul(X, W) + b\n",
    "    result = Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(18.2000)"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-b58f9438b932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/0729_transformer/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/0729_transformer/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "result.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 nn Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](img/pytorch_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 2., 3.],\n        [3., 4., 5.]])\ntorch.Size([2, 3])\n"
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dim 3, output dim 1\n",
    "linear_fn = nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Linear(in_features=3, out_features=1, bias=True)"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "linear_fn  # WX + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1.2229],\n        [1.8795]], grad_fn=<AddmmBackward>)\ntorch.Size([2, 1])\n"
    }
   ],
   "source": [
    "Y = linear_fn(X)\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(3.1024, grad_fn=<SumBackward0>)\n"
    }
   ],
   "source": [
    "Y = Y.sum()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Model(3, 1, 10)  # init(3, 1, 10)\n",
    "# input dimension: 3  /  output dimension: 1  / hidden dimension:  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.5040],\n        [0.7535]], grad_fn=<AddmmBackward>)"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "NN(X)  # forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d\n",
    "nn.RNNCell\n",
    "nn.LSTMCell\n",
    "nn.GRUCell\n",
    "nn.Transformer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch docs: https://pytorch.org/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sigmoid\n",
    "nn.ReLU\n",
    "nn.LeakyReLU\n",
    "nn.Tanh;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Dropout\n",
    "nn.BatchNorm2d\n",
    "nn.InstanceNorm2d\n",
    "nn.MaxPool2d\n",
    "nn.AvgPool2d;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퀴즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 X를 forwarding 시킬 수 있는 3 layer neural network를 만들어 보세요. 이때 hidden layer의 dimension은 자유롭게 선택하시고, activation function은 leaky relu를 사용하세요. Output의 dimension은 1입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 2., 3.],\n        [3., 4., 5.]])\ntorch.Size([2, 3])\n"
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear_3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MyModel(3, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.3120],\n        [-0.3973]], grad_fn=<AddmmBackward>)\ntorch.Size([2, 1])\n"
    }
   ],
   "source": [
    "# 이 부분이 돌아가서 output이 나와야 합니다\n",
    "print(NN(X))\n",
    "print(NN(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch 출처 및 유용한 링크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch docs: https://pytorch.org/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://pytorch.org/tutorials/\n",
    "2. https://github.com/yunjey/pytorch-tutorial\n",
    "3. https://github.com/bharathgs/Awesome-pytorch-list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('0729_transformer': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596003539248"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}