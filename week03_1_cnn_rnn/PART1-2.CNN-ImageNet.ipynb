{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krkka5jdobrD"
   },
   "source": [
    "# ImageNet 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1mt9bayoQhk"
   },
   "source": [
    "## ImageNet 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLpy6t3moQhl"
   },
   "source": [
    "ILSVRC: ImageNet Large Scale Visual Recognition Competetion[https://deepestdocs.readthedocs.io/en/latest/003_image_processing/0031/]<br>\n",
    "<p> ImageNet은 ILSVRC 챌린지에서 사용하는 데이터입니다. ImageNet 전 세계에서 모은 이미지들로 챌린지를 열어 누가 컴퓨터 비젼 분야에서 제일 뛰어난 기술을 갖고 있는지를 겨룹니다. 매년 새로운 승자가 등장하고, 그렇게 등장한 기술들은 거의 대부분 반드시 사용해야만 하는 기술이 되곤 합니다. </p>\n",
    "<p>1,000 종류의 1,281,167 개 데이터가 주어지고 데이터가 어떤 물체인지를 맞추는 챌린지입니다. 각 종류별 데이터의 갯수도 다릅니다. 분류 외에도 탐지(detection) 등 다른 부문도 있지만, 제일 유명한 것은 1,000 종류 분류입니다. 엄청나게 많은 데이터인데다, 전체를 합치면 200GB에 가깝습니다. 이 크기는 절대 GPU에 들어갈 수 없기 때문에 보통 특별한 방법을 써서 GPU 훈련을 시킵니다.</p> \n",
    "<p>논문에서 사용하는 ImageNet 데이터는 ILSVRC 2012 의 분류 문제에 사용된 데이터입니다. 실제로 ImageNet 데이터는 저게 전부가 아니고, 훨씬 많은 전 세계에서 모은 데이터들을 모아 놓은 사이트입니다. 다만 이 중 일부를 떼서 챌린지 용으로 사용하는 것 뿐입니다. ImageNet 회원이 되면 비상업적 목적으로 원본 이미지를 다운받을 수도 있고, 이미지의 URL만 받아 불러올 수도 있습니다. 하지만 훈련을 위해서는 역시 원본 이미지가 있어야 합니다. 이미지들의 크기도 전부 다르기 때문에 전처리도 필요합니다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68bUQJlRoQhm"
   },
   "source": [
    "## Tiny ImageNet\n",
    "<p>ImageNet은 200GB 넘어 다운받는데만도 하루 이상 걸리기 때문에, 오늘 실습에서는 Tiny ImageNet을 이용할 것입니다. Tiny ImageNet은 스탠포드 CS231N Convolutional Neural Networks for Visual Recognition 수업의 기본 코스 프로젝트에 사용되는 데이터셋입니다. </p>\n",
    "<p> Tiny Imagenet에는 200 개의 클래스가 있습니다. 각 이미지는 64 X 64로 축소 되었습니다. 각 클래스에는 500 개의 학습 이미지, 50 개의 검증 이미지 및 50 개의 테스트 이미지가 있습니다. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Is7gaWSoQhn"
   },
   "source": [
    "아래의 코드를 터미널 창에 입력하여 데이터셋을 다운받고 압축을 풀 수 있습니다. \n",
    "~~~\n",
    "wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "unzip tiny-imagenet-200.zip\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_Z0Cx7Dko71T",
    "outputId": "9ea4efda-c7e3-4b5c-fc5a-ecf8ccbbdb0a"
   },
   "outputs": [],
   "source": [
    "!curl http://cs231n.stanford.edu/tiny-imagenet-200.zip --output tiny-imagenet-200.zip\n",
    "!unzip tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJUeRnURooF3"
   },
   "source": [
    "## Package 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX5xDGehly80"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_SBx8i8l-C-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout, Add, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9cSNBhFEZqb"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzXueinBmTWf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl0xFDjiosNj"
   },
   "source": [
    "## 데이터셋 구조 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kud6ZoK7oskA",
    "outputId": "b90099a3-0269-48dd-f647-b167ab4f847f"
   },
   "outputs": [],
   "source": [
    "data_path = 'tiny-imagenet-200'\n",
    "\n",
    "# os.listdir을 통해 해당 path에 있는 폴더들을 리스트로 받아옵니다. \n",
    "os.listdir(os.path.join(data_path, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R7aPNgfDpFV_",
    "outputId": "9feca675-1fa5-4263-ca01-6b4041b9b969"
   },
   "outputs": [],
   "source": [
    "tmp_path = os.path.join(data_path, 'train')\n",
    "img_id = os.listdir(tmp_path)[0]\n",
    "print ('{0} 폴더의 이미지 갯수: {1}'.format(img_id, len(os.listdir(os.path.join(tmp_path, img_id, 'images')))))\n",
    "os.listdir(os.path.join(tmp_path, img_id, 'images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-7GoZhNqff1"
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9gH-VhHtDqH"
   },
   "source": [
    "### Train-set 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wC22IEUdpHLq"
   },
   "outputs": [],
   "source": [
    "# mini batch size를 16으로 설정합니다.\n",
    "BATCH_SIZE = 64\n",
    "# Tiny ImageNet의 class 수 200을 NUM_CLASSES에 저장합니다.\n",
    "NUM_CLASSES = 200\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "NUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\n",
    "NUM_VAL_IMAGES = 10000\n",
    "\n",
    "# train-set image가 저장되어있는 장소를 저장합니다.\n",
    "# validation-set image가 저장되어 있는 장소를 저장합니다.\n",
    "# test-set image가 저장되어 있는 장소를 저장합니다.\n",
    "BASE_DIR = './'\n",
    "TRAINING_IMAGES_DIR = BASE_DIR + 'tiny-imagenet-200/train/'\n",
    "VAL_IMAGES_DIR = BASE_DIR + 'tiny-imagenet-200/val/'\n",
    "TEST_IMAGES_DIR = BASE_DIR + 'tiny-imagenet-200/test/'\n",
    "\n",
    "# Tiny ImageNet의 기본 image size인 64를 저장합니다.\n",
    "IMAGE_SIZE = 64\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SUm-HPaVpcRn",
    "outputId": "4a908b11-1cc7-4df9-f21f-46f6c2481c4b"
   },
   "outputs": [],
   "source": [
    "# Train-set을 읽어와 images에 이미지 데이터, labels에 정답, names에 이미지 파일 이름을 저장합니다.\n",
    "images = []\n",
    "labels = []\n",
    "names = []\n",
    "\n",
    "for label in tqdm(os.listdir(TRAINING_IMAGES_DIR)):\n",
    "  #print (label)\n",
    "  for example in os.listdir(os.path.join(TRAINING_IMAGES_DIR, label, 'images')):\n",
    "    image_file = os.path.join(TRAINING_IMAGES_DIR, label, 'images', example)\n",
    "    image_data = Image.open(image_file)\n",
    "    image_data = image_data.resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "    image_data = np.array(image_data)\n",
    "    \n",
    "    if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "      images.append(image_data)\n",
    "      labels.append(label)\n",
    "      names.append(example)\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)\n",
    "names = np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctqBAUtkqJ_v"
   },
   "outputs": [],
   "source": [
    "# 저장해놓은 데이터를 헷갈리지 않도록 training이 붙은 변수에 복사합니다.\n",
    "training_images, training_labels, training_files = images, labels, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6skwsactZ7_"
   },
   "source": [
    "### Validation-set 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4fvJOgAQqor-",
    "outputId": "33cffe43-7f96-4825-98e7-dc71e4980b1c"
   },
   "outputs": [],
   "source": [
    "# VAL_IMAGES_DIR 위치에는 images 폴더와 val_annotations.txt 파일이 있습니다.\n",
    "os.listdir(VAL_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "SVqZVRXxtpzW",
    "outputId": "cd8ee9d7-4083-48f4-f369-7e67d6a7b51e"
   },
   "outputs": [],
   "source": [
    "# train 구조와는 다르게 validation 은 images 파일안에 모든 이미지가 들어있고 \n",
    "# 정답은 val_annotations.txt에 있습니다.\n",
    "# val_annoations.txt를 읽어옵니다. \n",
    "val_data = pd.read_csv(VAL_IMAGES_DIR + 'val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFX3B8ruyf_q"
   },
   "outputs": [],
   "source": [
    "name2label = val_data.set_index('File')['Class'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r5Ct1ad2y2h-",
    "outputId": "7121f4ab-0790-4402-8321-4d8e874f5294"
   },
   "outputs": [],
   "source": [
    "name2label['val_1.JPEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TA4kauocuXiR",
    "outputId": "eeafef69-ce17-46fb-b503-c1501f3b25d0"
   },
   "outputs": [],
   "source": [
    "# Validation-set을 읽어와 images에 이미지 데이터, labels에 정답, names에 이미지 파일 이름을 저장합니다.\n",
    "images = []\n",
    "labels = []\n",
    "names = []\n",
    "\n",
    "\n",
    "for example in tqdm(os.listdir(os.path.join(VAL_IMAGES_DIR, 'images'))):\n",
    "  # print (example)\n",
    "  image_file = os.path.join(VAL_IMAGES_DIR, 'images', example)\n",
    "  image_data = mpimg.imread(image_file)\n",
    "  label = name2label[example]\n",
    "\n",
    "  if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "    images.append(image_data)\n",
    "    labels.append(label)\n",
    "    names.append(example)\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)\n",
    "names = np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEM1W4o7tvwo"
   },
   "outputs": [],
   "source": [
    "# 저장해놓은 데이터를 헷갈리지 않도록 validation 붙은 변수에 복사합니다.\n",
    "validation_images, validation_labels, validation_files = images, labels, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxGS67Tyw5_x"
   },
   "source": [
    "### Test-set 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OpRKruQ3w869",
    "outputId": "64ec99f7-3d68-4668-e8c4-7cfaf595bc93"
   },
   "outputs": [],
   "source": [
    "# TEST_IMAGES_DIR 위치에는 images 폴더만 있습니다.\n",
    "# test-set에 대한 정답은 공개되어 있지 않으며 아래의 사이트에 정답을 제출하여 성적을 확인할 수 있습니다. \n",
    "# https://tiny-imagenet.herokuapp.com/\n",
    "os.listdir(TEST_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UYVel9-tzJrx",
    "outputId": "c2ba0150-7220-4c67-8340-1474422a346b"
   },
   "outputs": [],
   "source": [
    "# Test-set을 읽어와 images에 이미지 데이터, names에 이미지 파일 이름을 저장합니다.\n",
    "images = []\n",
    "names = []\n",
    "\n",
    "\n",
    "for example in tqdm(os.listdir(os.path.join(TEST_IMAGES_DIR, 'images'))):\n",
    "  # print (example)\n",
    "  image_file = os.path.join(TEST_IMAGES_DIR, 'images', example)\n",
    "  image_data = mpimg.imread(image_file)\n",
    "\n",
    "  if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "    images.append(image_data)\n",
    "    names.append(example)\n",
    "images = np.asarray(images)\n",
    "names = np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Luz6oh50alm"
   },
   "outputs": [],
   "source": [
    "# 저장해놓은 데이터를 헷갈리지 않도록 testing 붙은 변수에 복사합니다.\n",
    "testing_images, testing_files = images, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvIl0ZeR3X1Y"
   },
   "source": [
    "## 레이블이 무슨 의미일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OFpeHpky3eis",
    "outputId": "92ebe566-8ba9-4072-89e0-e002f0fc0f0f"
   },
   "outputs": [],
   "source": [
    "# words.txt에 레이블이 무슨 의미인지 저장되어 있습니다.\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "jBPGe5dH3q-B",
    "outputId": "9e97afb7-aa92-4457-f5bf-a400a371f750"
   },
   "outputs": [],
   "source": [
    "# label에 매칭되는 word를 label2word에 저장합니다.\n",
    "label2word = pd.read_csv(os.path.join(data_path, 'words.txt'), sep='\\t', header=None, names=['label', 'word'])\n",
    "label2word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KN3Gt1_d4roi"
   },
   "outputs": [],
   "source": [
    "# 이용하기 쉽도록 dataframe에서 label을 key로, word를 value로 가진 dictionary로 바꿉니다.\n",
    "label2word = label2word.set_index('label')['word'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYrpUsqU2MD4"
   },
   "source": [
    "## 이미지 plot 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNLrhZVp2Oou"
   },
   "outputs": [],
   "source": [
    "def plot_object(data):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    image = data\n",
    "    plt.imshow(image.astype(np.uint8), cmap = matplotlib.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "colab_type": "code",
    "id": "YHaHYUVM2Qjm",
    "outputId": "aa8f3576-d166-4a5c-8eb9-9b840332e813"
   },
   "outputs": [],
   "source": [
    "for label, example in list(zip(training_labels, training_images))[1000:1005]:\n",
    "  print ('Label: {0} / {1}'.format(label, label2word[label]))\n",
    "  plot_object(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPzPM-Wa_Sg-"
   },
   "source": [
    "## ResNet 구조 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7VtlMnE_qxh"
   },
   "outputs": [],
   "source": [
    "resnet = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "8_4P0OFMnnw2",
    "outputId": "81c6a901-07ac-4d5d-9902-5303f58fad7b"
   },
   "outputs": [],
   "source": [
    "url = 'https://d17fnq9dkz9hgj.cloudfront.net/uploads/2018/04/Pomeranian_02.jpg' # 귀여운 강아지 이미지\n",
    "img = Image.open(urlopen(url))\n",
    "img = img.resize((224, 224))\n",
    "imshow(np.asarray(img))\n",
    "\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = resnet.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MojJB1tV2nFR",
    "outputId": "10535258-78b1-4e99-d0b3-207e5dd56e57"
   },
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCNSDDLt_3qi"
   },
   "source": [
    "## Tiny ImageNet에 맞게 Transfer learning 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5w-hxphV_9gI"
   },
   "outputs": [],
   "source": [
    "# 몇 epoch을 학습할지 EPOCH에 저장합니다.\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "hEPh6NALAX1U",
    "outputId": "ca4b2d83-deb8-4928-88b3-4cedd84c9d8a"
   },
   "outputs": [],
   "source": [
    "# fully connected layer를 제외한 resnet50 imagenet pretrained model을 생성하여 resnet_conv에 저장합니다.\n",
    "# pretrained된 모델은 imagenet의 200 GB가 넘는 train-set에 대해 학습되어져 있습니다.\n",
    "resnet_conv = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ6mEkVoAcVZ"
   },
   "outputs": [],
   "source": [
    "# resnet_conv의 모든 layer를 학습되지 않도록 설정합니다.\n",
    "for layer in resnet_conv.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdntJwxiAgFe"
   },
   "outputs": [],
   "source": [
    "# model을 새로 생성합니다.\n",
    "model = Sequential()\n",
    "# model에 resnet_conv를 추가합니다.\n",
    "model.add(resnet_conv)\n",
    "# resnet_conv의 마지막 convolution을 한 줄로 펼칩니다.\n",
    "model.add(Flatten())\n",
    "# 1024개의 node를 output으로 가지는 fully connected layer를 만듭니다.\n",
    "# activation function은 relu로 설정합니다.\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "# NUM_CLASSES만큼의 노드를 만들고 softmax를 연결하여 확률이 출력되도록 합니다.\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFO6W4SEAjPM"
   },
   "outputs": [],
   "source": [
    "# cost function은 multi class classification에 일반적으로 사용하는 categorical crossentropy를 설정합니다.\n",
    "# optimizer는 Momemtum을 사용하고 learning rate은 0.001, momumtum 값은 0.9로 설정합니다.\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "#  optimizer=optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "   optimizer=optimizers.Adam(lr=0.001),\n",
    "   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0X-RUFbJA2rO"
   },
   "outputs": [],
   "source": [
    "# train-set image는 resnet50용 preproces_input을 사용하여 preprocess를 합니다.\n",
    "# 각종 data augmentation 기법을 사용하여 무작위로 확대 축소 회전 반전 등을 해줍니다.\n",
    "train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            zoom_range=0.3,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            rotation_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wurhhTUqBR02",
    "outputId": "38c89087-274d-4021-9595-ed301bce8328"
   },
   "outputs": [],
   "source": [
    "# TRAINING_IMAGES_DIR에 저장되어 있는 image data들을 train-set data로 사용합니다.\n",
    "# image data들은 IMAGE_SIZE * IMAGE_SIZE로 변환하여 사용합니다.\n",
    "# mini batch size는 BATCH_SIZE로 설정합니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "          TRAINING_IMAGES_DIR,\n",
    "          target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "          class_mode=\"categorical\",\n",
    "          batch_size=BATCH_SIZE)\n",
    "label2id = (train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "danRTHCZBiEk"
   },
   "outputs": [],
   "source": [
    "# validation-set image는 resnet50용 preproces_input을 사용하여 preprocess를 합니다.\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "OPz5F30CN1hR",
    "outputId": "cd237ea7-3940-4f80-ba99-41eafb37fc8b"
   },
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v207p6iwB4Gs",
    "outputId": "c3bac90c-db71-49dd-9753-f247608cf320"
   },
   "outputs": [],
   "source": [
    "# val_data를 이용하여 validation dataset을 구성합니다. \n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "          dataframe=val_data,\n",
    "          directory=os.path.join(VAL_IMAGES_DIR, 'images'),\n",
    "          x_col=\"File\",\n",
    "          y_col=\"Class\",\n",
    "          target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "          class_mode=\"categorical\",\n",
    "          batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRUb3QiSPR7l"
   },
   "outputs": [],
   "source": [
    "# SETP_SIZE는 한 epoch 당 몇개의 mini batch를 이용할 지 결정합니다. \n",
    "# 원래 STEP_SIZE_TRAIN으로 하면 한 epoch당 약 30분 정도 학습 시간이 소요됩니다.\n",
    "STEP_SIZE_TRAIN = 5 # 5 # train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = 1 # 1 # validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9utq3KvSCGQh",
    "outputId": "5532c2f7-35e7-4c0e-cfd1-b6346781fdae"
   },
   "outputs": [],
   "source": [
    "# train-set을 이용하여 모델을 학습하고 validation-set을 이용하여 모델을 평가합니다. \n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      epochs=EPOCHS,\n",
    "      steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=STEP_SIZE_VALID,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ar7u5jBXDWdx",
    "outputId": "70e3275b-ede5-45a8-aefe-66310ab39aae"
   },
   "outputs": [],
   "source": [
    "# evaluate_generator를 이용하여 모델의 성능을 평가할 수 도 있습니다. \n",
    "model.evaluate_generator(generator=validation_generator, steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQdM9SyMO77Q"
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'],'-o')\n",
    "    plt.plot(history.history['val_loss'],'-o')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc=0)\n",
    "    \n",
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'],'-o')\n",
    "    plt.plot(history.history['val_accuracy'],'-o')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "NQCnn33vOz57",
    "outputId": "c253c00b-b383-45c6-da34-8e73e96545c6"
   },
   "outputs": [],
   "source": [
    "# 학습하는 동안 모델의 정확도와 손실도가 어떻게 변화하였는지 그래프로 확입합니다. \n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NALJH8lWZXh6"
   },
   "source": [
    "## Test-set에 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W-dfOQPNZaPr",
    "outputId": "8968b5f7-01f5-4aa3-f55c-a7b6937bcc7c"
   },
   "outputs": [],
   "source": [
    "# test-set을 읽어와 images에 이미지 데이터, labels에 정답, names에 이미지 파일 이름을 저장합니다.\n",
    "images = []\n",
    "names = []\n",
    "\n",
    "\n",
    "for example in tqdm(os.listdir(os.path.join(TEST_IMAGES_DIR, 'images'))):\n",
    "  # print (example)\n",
    "  image_file = os.path.join(TEST_IMAGES_DIR, 'images', example)\n",
    "  image_data = mpimg.imread(image_file)\n",
    "\n",
    "  if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "    images.append(image_data)\n",
    "    names.append(example)\n",
    "images = np.asarray(images)\n",
    "names = np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36v1j6AdakiS"
   },
   "outputs": [],
   "source": [
    "# 저장해놓은 데이터를 헷갈리지 않도록 test 붙은 변수에 복사합니다.\n",
    "test_images, test_files = images, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3tLkdna_uw"
   },
   "outputs": [],
   "source": [
    "# test-set image는 resnet50용 preproces_input을 사용하여 preprocess를 합니다.\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ri88e1e_eb6h"
   },
   "outputs": [],
   "source": [
    "# test-set에는 정답없이 이미지만 존재하기 때문에 데이터셋을 읽어오기 쉽도록 dataframe을 만듭니다. \n",
    "# File 컬럼에는 이미지 파일 이름이 들어가 있고, Class에는 가짜 label이 들어있습니다. \n",
    "test_data = pd.DataFrame(index=range(len(test_images)), columns=['File', 'Class'])\n",
    "\n",
    "test_data['File'] = test_files\n",
    "test_data['Class'] = 'n01443537' # Trash value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BaioXSGkhP3E"
   },
   "outputs": [],
   "source": [
    "# 예측하기 쉽도록 test_data를 파일 이름 순으로 정렬합니다. \n",
    "test_data = test_data.sort_values(by=['File'])\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sCjLZ3mfbZVv",
    "outputId": "d4e9b090-4151-44e4-e591-671c3868654b"
   },
   "outputs": [],
   "source": [
    "# test_data를 이용하여 test-set을 읽어옵니다. \n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "          dataframe=test_data,\n",
    "          directory=os.path.join(TEST_IMAGES_DIR, 'images'),\n",
    "          x_col=\"File\",\n",
    "          y_col=\"Class\",\n",
    "          target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "          class_mode=None,\n",
    "          batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5kQoDtjbrJw"
   },
   "outputs": [],
   "source": [
    "# STEP_SIZE는 한 epoch 당 몇 개의 mini batch를 이용할지 결정합니다. \n",
    "STEP_SIZE_TEST = 1 # test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhBea80Vbdq3"
   },
   "outputs": [],
   "source": [
    "# test-set에 대하여 예측합니다. \n",
    "# preds = model.predict_generator(test_generator, steps = STEP_SIZE_TEST)\n",
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tK9vs34KcNDC"
   },
   "outputs": [],
   "source": [
    "# 모델에서 예측값은 200개의 클래스에 대한 확률로 나타나므로, 가장 확률이 높은 label의 index를 저장합니다. \n",
    "predicted_class_indices = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WCSQ5aKlcYI-",
    "outputId": "12148b6d-bef9-4cee-a330-65daa05cd64f"
   },
   "outputs": [],
   "source": [
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0siRzYYcb9Z"
   },
   "outputs": [],
   "source": [
    "# index에 해당하는 label을 predictions에 저장합니다. \n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDZTfGJnf7_N"
   },
   "outputs": [],
   "source": [
    "# predictions를 이용하여 Class에 예측 label (class)를 저장합니다. \n",
    "test_data.loc[:len(predictions)-1, 'Class'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "WPNFmRnMi6Sy",
    "outputId": "ee159998-1eda-4b70-80a2-9ece7eb1ef58"
   },
   "outputs": [],
   "source": [
    "# 그림과 그림에 해당하는 예측값을 나타냅니다. \n",
    "cnt = 0\n",
    "for name, label in zip(test_data['File'].values, test_data['Class'].values):\n",
    "    image_data = Image.open(os.path.join(TEST_IMAGES_DIR, 'images', name))\n",
    "    imshow(np.asarray(image_data))\n",
    "    plt.title(label2word[label])\n",
    "    if cnt >= 3:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8n-q5RUNjXou"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2ssk5jHgeOA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "수업실습.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
