{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020.07.27 VAE Tutorial\n",
    "#### TA : Taewook Nam @ MLAI (namsan@kaist.ac.kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Implementation of VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Implement neural network encoder & decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "  h_dim = 500\n",
    "\n",
    "  def __init__(self, x_shape, z_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    x_dim = np.prod(x_shape)\n",
    "    self.z_dim = z_dim\n",
    "\n",
    "    self.encoder = Sequential([\n",
    "        Flatten(),\n",
    "        Dense(self.h_dim, activation='relu'),\n",
    "        Dense(self.h_dim, activation='relu'),\n",
    "    ])\n",
    "    self.mu_dense = Dense(z_dim)\n",
    "    self.sigma_dense = Dense(z_dim, activation='softplus')\n",
    "\n",
    "    self.decoder = Sequential([\n",
    "        Dense(self.h_dim, activation='relu'),\n",
    "        Dense(self.h_dim, activation='relu'),\n",
    "        Dense(x_dim, activation='sigmoid'),\n",
    "        Reshape(x_shape)\n",
    "    ])\n",
    "\n",
    "  def encode(self, x):\n",
    "    h = self.encoder(x)\n",
    "    z_mu = self.mu_dense(h)\n",
    "    z_sigma = self.sigma_dense(h)\n",
    "    return z_mu, z_sigma\n",
    "\n",
    "  def decode(self, z):\n",
    "    return self.decoder(z)\n",
    "\n",
    "vae = VAE((28, 28), 2)  # z is 2-d because we need to visualize the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Implement loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_elbo(x, x_reconst, z_mu, z_sigma):\n",
    "  log_likelihood = tf.reduce_sum(\n",
    "    x*tf.math.log(x_reconst+1e-6) + (1-x)*tf.math.log(1-x_reconst+1e-6),\n",
    "    axis=(1,2)\n",
    "  )\n",
    "  kl = 0.5 * tf.reduce_sum(\n",
    "    z_mu**2 + z_sigma**2 - tf.math.log(z_sigma**2) - 1,\n",
    "    axis=1\n",
    "  )\n",
    "  elbo = tf.reduce_mean(log_likelihood - kl)\n",
    "  return elbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Prepare data (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = tf.cast(x_train / 255.0, tf.float32)\n",
    "x_test = tf.cast(x_test / 255.0, tf.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train).shuffle(10000).batch(100)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(x_test).batch(100)### 3) Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Optimize VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch_i in trange(100):\n",
    "  for x in train_ds:\n",
    "    with tf.GradientTape() as tape:\n",
    "      z_mu, z_sigma = vae.encode(x)\n",
    "      z_dist = tfp.distributions.Normal(z_mu, z_sigma)\n",
    "      z = z_dist.sample()\n",
    "      x_reconst = vae.decode(z)\n",
    "        \n",
    "      elbo = compute_elbo(x, x_reconst, z_mu, z_sigma)\n",
    "      loss = -elbo\n",
    "    gradients = tape.gradient(loss, vae.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "\n",
    "  if (epoch_i+1) % 5 == 0:\n",
    "    vae.save_weights(f'ckpt/{epoch_i + 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_i = 100\n",
    "vae.load_weights(f'ckpt/{ckpt_i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Visualize encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "z_mu, _ = vae.encode(x_test[:n_points])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "scatter = plt.scatter(\n",
    "    z_mu[:, 0], z_mu[:, 1],\n",
    "    c=[f'C{y_test[i]}' for i in range(n_points)],\n",
    "    label=[y_test[i] for i in range(n_points)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Visualize reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "z_mu, _ = vae.encode(x_test)\n",
    "x_reconst = vae.decode(z_mu)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(x_test[idx])\n",
    "ax2.imshow(x_reconst[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Visualize learned latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_range = np.arange(-1, 1, 0.1)\n",
    "z_grid = np.stack(np.meshgrid(z_range, z_range), axis=-1)\n",
    "\n",
    "z_grid_flat = z_grid.reshape(400, 2)\n",
    "x_reconst_flat = vae.decode(tf.convert_to_tensor(z_grid_flat))\n",
    "x_reconst = x_reconst_flat.numpy().reshape(20, 20, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_merged = x_reconst.swapaxes(1, 2).reshape(20*28, 20*28)\n",
    "plt.imshow(x_merged)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('0727_generative': conda)",
   "language": "python",
   "name": "python_defaultSpec_1595830637998"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}